# ğŸš€ Post-Quantum Hyperledger Fabric Benchmark

A research-oriented framework for evaluating the **performance impact of post-quantum cryptography (PQC)** on **Hyperledger Fabric**.

This repository supports experiments with **ECDSA**, **PQC-only**, and **Hybrid (ECDSA + PQC)** signing schemes to assess quantum-resilient transaction flows.

---

## ğŸ¯ Purpose

This project provides a reproducible environment to:

* Benchmark PQC algorithms (Dilithium, Falcon, etc.) integrated into Fabric
* Measure performance impact on transaction latency, throughput, endorsement, and ordering
* Test hybrid cryptographic models for quantum-secure enterprise blockchains
* Support rigorous academic research with statistical analysis and reproducible experiments

---

## ğŸ“¦ Key Features

* Docker-based reproducible Hyperledger Fabric network
* Pluggable cryptographic modules (ECDSA, PQC, Hybrid)
* Automated benchmarking through Hyperledger Caliper
* Multi-VM orchestration for distributed testing
* Comprehensive data collection and analysis pipeline
* Research-grade documentation and experiment protocols

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ docs/              # ğŸ“š Technical Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # System design and PQC integration points
â”‚   â”œâ”€â”€ CRYPTOGRAPHIC_MODES.md       # ECDSA, PQC-only, and Hybrid specifications
â”‚   â”œâ”€â”€ METRICS_SPECIFICATION.md     # Performance metrics definitions
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md          # Setup and installation instructions
â”‚   â”œâ”€â”€ BENCHMARK_PROTOCOL.md        # Experimental methodology
â”‚   â”œâ”€â”€ DATASET_SPECIFICATION.md     # Data format and naming conventions
â”‚   â”œâ”€â”€ RESULTS_ANALYSIS.md          # Statistical analysis guidelines
â”‚   â””â”€â”€ IMPLEMENTATION_NOTES.md      # Technical challenges and solutions
â”‚
â”œâ”€â”€ src/               # ğŸ’» Core Application Code
â”‚   â”œâ”€â”€ fabric/        # Hyperledger Fabric modifications and chaincode
â”‚   â”œâ”€â”€ pqc/           # Post-quantum cryptographic implementations
â”‚   â””â”€â”€ sdk/           # Client SDK extensions for PQC signing
â”‚
â”œâ”€â”€ tools/             # âš™ï¸ Automation & Benchmarking
â”‚   â”œâ”€â”€ benchmark/     # Caliper configurations and workload generators
â”‚   â”œâ”€â”€ scripts/       # Deployment, testing, and data collection scripts
â”‚   â””â”€â”€ monitoring/    # Performance monitoring and logging utilities
â”‚
â”œâ”€â”€ simulations/       # ğŸ§ª Experimental Scenarios
â”‚   â”œâ”€â”€ scenarios/     # Workload definitions (low/medium/high load)
â”‚   â”œâ”€â”€ networks/      # Network topology configurations (2/4/10/20 nodes)
â”‚   â””â”€â”€ results/       # Simulation outputs and preliminary data
â”‚
â”œâ”€â”€ tests/             # âœ… Test Suites
â”‚   â”œâ”€â”€ unit/          # Unit tests for PQC modules and CSP implementations
â”‚   â”œâ”€â”€ integration/   # Integration tests for Fabric + PQC workflows
â”‚   â””â”€â”€ e2e/           # End-to-end scenario validation tests
â”‚
â”œâ”€â”€ data/              # ğŸ“Š Dataset Management
â”‚   â”œâ”€â”€ raw/           # Raw benchmark outputs (CSV, logs)
â”‚   â”œâ”€â”€ processed/     # Cleaned and aggregated analysis-ready data
â”‚   â””â”€â”€ fixtures/      # Test data and seed configurations
â”‚
â”œâ”€â”€ analysis/          # ğŸ“ˆ Data Analysis & Visualization
â”‚   â”œâ”€â”€ notebooks/     # Jupyter notebooks for exploratory analysis
â”‚   â”œâ”€â”€ scripts/       # Statistical analysis scripts (Python/R)
â”‚   â””â”€â”€ figures/       # Generated charts and graphs for publications
â”‚
â”œâ”€â”€ docker/            # ğŸ³ Container Infrastructure
â”‚   â”œâ”€â”€ images/        # Custom Dockerfiles (Fabric+PQC, Caliper)
â”‚   â”œâ”€â”€ compose/       # Docker Compose orchestration files
â”‚   â””â”€â”€ configs/       # Fabric network configurations (crypto-config, configtx)
â”‚
â”œâ”€â”€ vm/                # ğŸ–¥ï¸ Virtual Machine Orchestration
â”‚   â”œâ”€â”€ provisioning/  # Vagrant/Terraform scripts for VM infrastructure
â”‚   â”œâ”€â”€ ansible/       # Ansible playbooks for automated deployment
â”‚   â””â”€â”€ inventory/     # VM inventory and network topology definitions
â”‚
â””â”€â”€ artifacts/         # ğŸ“¦ Build Outputs (gitignored)
    â”œâ”€â”€ binaries/      # Compiled Fabric binaries and PQC libraries
    â””â”€â”€ certificates/  # Generated cryptographic materials (MSP, TLS)
```

---

## ğŸš€ Quick Start

### Prerequisites

* Docker 20.10+ and Docker Compose 2.0+
* Python 3.8+ (for analysis scripts)
* 16GB RAM minimum (32GB recommended for multi-node experiments)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/pqc-fabric-benchmark.git
cd pqc-fabric-benchmark

# Deploy the Fabric network with ECDSA baseline
./tools/scripts/deploy-network.sh --mode ecdsa

# Run benchmark
./tools/scripts/run-benchmark.sh --workload low --duration 300

# Collect results
./tools/scripts/collect-data.sh --output data/raw/
```

For detailed setup instructions, see [`docs/DEPLOYMENT_GUIDE.md`](docs/DEPLOYMENT_GUIDE.md).

---

## ğŸ”¬ Experimental Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| **ECDSA** | Classical elliptic curve signatures | Performance baseline |
| **PQC-Only** | Pure post-quantum signatures (Dilithium, Falcon) | End-state quantum resistance |
| **Hybrid** | Dual ECDSA + PQC verification | Transition strategy evaluation |

See [`docs/CRYPTOGRAPHIC_MODES.md`](docs/CRYPTOGRAPHIC_MODES.md) for detailed specifications.

---

## ğŸ“Š Performance Metrics

* **Transaction throughput** (TPS)
* **End-to-end latency** (ms)
* **Signature generation/verification time** (Î¼s)
* **Resource utilization** (CPU, RAM)
* **Block size and commit time**
* **Network overhead** (payload size)

Full metric definitions: [`docs/METRICS_SPECIFICATION.md`](docs/METRICS_SPECIFICATION.md)

---

## ğŸ“ˆ Data Analysis

Analysis workflows are available in [`analysis/`](analysis/):

```bash
# Generate summary statistics
python analysis/scripts/compute_statistics.py --input data/raw/ --output data/processed/

# Create visualizations
jupyter notebook analysis/notebooks/performance_comparison.ipynb
```

---

## ğŸ§ª Running Experiments

```bash
# Run all cryptographic modes with multiple load profiles
./tools/scripts/run-experiments.sh --modes all --loads all --runs 5

# Analyze results
python analysis/scripts/generate_report.py --data data/raw/ --output analysis/figures/
```

See [`docs/BENCHMARK_PROTOCOL.md`](docs/BENCHMARK_PROTOCOL.md) for the complete experimental methodology.

---

## ğŸ“š Documentation

Comprehensive technical documentation is available in [`docs/`](docs/):

* **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System design and integration approach
* **[CRYPTOGRAPHIC_MODES.md](docs/CRYPTOGRAPHIC_MODES.md)** - Detailed algorithm specifications
* **[DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)** - Step-by-step setup instructions
* **[BENCHMARK_PROTOCOL.md](docs/BENCHMARK_PROTOCOL.md)** - Experimental methodology
* **[DATASET_SPECIFICATION.md](docs/DATASET_SPECIFICATION.md)** - Data format and structure
* **[RESULTS_ANALYSIS.md](docs/RESULTS_ANALYSIS.md)** - Statistical analysis guidelines

---

## ğŸ¤ Contributing

Contributions are welcome! Please see our contributing guidelines and code of conduct.

---

## ğŸ“§ Contact

For questions or collaboration inquiries:

* **Email**: antonio.pierro@gmail.com
* **Issues**: [GitHub Issues](https://github.com/devw/quantum-ledger/issues)

<!-- ---

## ğŸ“ Citation

If you use this framework in your research, please cite:

```bibtex
@article{yourname2025pqc,
  title={Performance Analysis of Post-Quantum Cryptography in Hyperledger Fabric},
  author={Your Name and Co-authors},
  journal={Journal Name},
  year={2025}
}
``` -->

---

## ğŸ™ Acknowledgments

* Hyperledger Fabric community
* Open Quantum Safe (liboqs) project
* NIST Post-Quantum Cryptography Standardization initiative

---

## ğŸ“œ License

**CC BY-NC 4.0** â€“ Free for non-commercial use. Commercial use requires written permission.
